{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b7732a-6e41-4171-9379-67fab3939bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4b64eb-2235-41a8-b804-321416296c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "NUM_FRAMES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d096df-5893-441a-ac69-601bb2336ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(video_path, num_frames=NUM_FRAMES):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    if frame_count == 0:\n",
    "        print(\"Error: Video is empty or corrupted.\")\n",
    "        return None\n",
    "    \n",
    "    interval = max(1, frame_count // num_frames)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    if len(frames) != num_frames:\n",
    "        print(\"Error: Not enough frames extracted. Check video file.\")\n",
    "        return None\n",
    "    \n",
    "    frames = np.array(frames) / 255.0\n",
    "    return frames.reshape(num_frames, IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ab87b-0934-40bc-943a-2f74b2bdb09d",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "639a8693-2687-40e8-82f1-bbb8cf152228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_video_lengths(data_path):\n",
    "    video_lengths = []\n",
    "    \n",
    "    for video_name in os.listdir(data_path):\n",
    "        video_path = os.path.join(data_path, video_name)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        duration = frame_count / fps if fps > 0 else 0\n",
    "        video_lengths.append(duration)\n",
    "        cap.release()\n",
    "        \n",
    "    return video_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6676dbe1-8135-4d71-bb15-7a9998c82416",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_path = r\"C:\\Users\\LEGION\\Desktop\\Violence Detection_O\\Violence Detection\\train_violence\"\n",
    "non_violence_path = r\"C:\\Users\\LEGION\\Desktop\\Violence Detection_O\\Violence Detection\\train_non_violence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9383f8a-70a6-48d9-9cc6-77a70f5455c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_durations = analyze_video_lengths(violence_path)\n",
    "non_violence_durations = analyze_video_lengths(non_violence_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b135593-1b21-4193-a360-ada82bad54fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
